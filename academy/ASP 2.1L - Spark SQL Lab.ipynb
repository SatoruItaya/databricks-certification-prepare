{"cells":[{"cell_type":"markdown","source":["-sandbox\n\n<div style=\"text-align: center; line-height: 0; padding-top: 9px;\">\n  <img src=\"https://databricks.com/wp-content/uploads/2018/03/db-academy-rgb-1200px.png\" alt=\"Databricks Learning\" style=\"width: 600px\">\n</div>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"cf33265a-9213-4993-9603-3fb02322fc82"}}},{"cell_type":"markdown","source":["# Spark SQL Lab\n\n##### Tasks\n1. Create a DataFrame from the **`events`** table\n1. Display the DataFrame and inspect its schema\n1. Apply transformations to filter and sort **`macOS`** events\n1. Count results and take the first 5 rows\n1. Create the same DataFrame using a SQL query\n\n##### Methods\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.SparkSession.html?highlight=sparksession\" target=\"_blank\">SparkSession</a>: **`sql`**, **`table`**\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a> transformations: **`select`**, **`where`**, **`orderBy`**\n- <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a> actions: **`select`**, **`count`**, **`take`**\n- Other <a href=\"https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrame.html\" target=\"_blank\">DataFrame</a> methods: **`printSchema`**, **`schema`**, **`createOrReplaceTempView`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2368a244-9d1a-4551-aa1c-8b140f2ba9e0"}}},{"cell_type":"code","source":["%run ../Includes/Classroom-Setup-SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a0c91a5d-57f4-45e7-901f-483e638798c0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Deleted the working directory dbfs:/user/si@elisaandgeeks.com/dbacademy/aspwd/asp_2_1l_spark_sql_lab\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Deleted the working directory dbfs:/user/si@elisaandgeeks.com/dbacademy/aspwd/asp_2_1l_spark_sql_lab\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Your working directory is\ndbfs:/user/si@elisaandgeeks.com/dbacademy/aspwd\n\nThe source for this dataset is\nwasbs://courseware@dbacademy.blob.core.windows.net/apache-spark-programming-with-databricks/v02/\n\nSkipping install of existing dataset to\ndbfs:/user/si@elisaandgeeks.com/dbacademy/aspwd/datasets\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Your working directory is\ndbfs:/user/si@elisaandgeeks.com/dbacademy/aspwd\n\nThe source for this dataset is\nwasbs://courseware@dbacademy.blob.core.windows.net/apache-spark-programming-with-databricks/v02/\n\nSkipping install of existing dataset to\ndbfs:/user/si@elisaandgeeks.com/dbacademy/aspwd/datasets\n"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Out[53]: DataFrame[key: string, value: string]","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Out[53]: DataFrame[key: string, value: string]"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"","textData":null,"removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"htmlSandbox","arguments":{}}},"output_type":"display_data","data":{"text/html":[""]}}],"execution_count":0},{"cell_type":"markdown","source":["### 1. Create a DataFrame from the **`events`** table\n- Use SparkSession to create a DataFrame from the **`events`** table"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c58ec7b5-a106-4205-b48c-b240b0279a0c"}}},{"cell_type":"code","source":["# TODO\nevents_df = spark.table(\"events\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9d586e76-1248-42da-9d79-8188b1e23acf"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 2. Display DataFrame and inspect schema\n- Use methods above to inspect DataFrame contents and schema"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc4276f1-d89a-40bf-a00f-949fb52c12d0"}}},{"cell_type":"code","source":["# TODO\nevents_df.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"78cf2e8b-605d-4e4c-873d-abd2da62afc6"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"root\n |-- device: string (nullable = true)\n |-- ecommerce: struct (nullable = true)\n |    |-- purchase_revenue_in_usd: double (nullable = true)\n |    |-- total_item_quantity: long (nullable = true)\n |    |-- unique_items: long (nullable = true)\n |-- event_name: string (nullable = true)\n |-- event_previous_timestamp: long (nullable = true)\n |-- event_timestamp: long (nullable = true)\n |-- geo: struct (nullable = true)\n |    |-- city: string (nullable = true)\n |    |-- state: string (nullable = true)\n |-- items: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- coupon: string (nullable = true)\n |    |    |-- item_id: string (nullable = true)\n |    |    |-- item_name: string (nullable = true)\n |    |    |-- item_revenue_in_usd: double (nullable = true)\n |    |    |-- price_in_usd: double (nullable = true)\n |    |    |-- quantity: long (nullable = true)\n |-- traffic_source: string (nullable = true)\n |-- user_first_touch_timestamp: long (nullable = true)\n |-- user_id: string (nullable = true)\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["root\n |-- device: string (nullable = true)\n |-- ecommerce: struct (nullable = true)\n |    |-- purchase_revenue_in_usd: double (nullable = true)\n |    |-- total_item_quantity: long (nullable = true)\n |    |-- unique_items: long (nullable = true)\n |-- event_name: string (nullable = true)\n |-- event_previous_timestamp: long (nullable = true)\n |-- event_timestamp: long (nullable = true)\n |-- geo: struct (nullable = true)\n |    |-- city: string (nullable = true)\n |    |-- state: string (nullable = true)\n |-- items: array (nullable = true)\n |    |-- element: struct (containsNull = true)\n |    |    |-- coupon: string (nullable = true)\n |    |    |-- item_id: string (nullable = true)\n |    |    |-- item_name: string (nullable = true)\n |    |    |-- item_revenue_in_usd: double (nullable = true)\n |    |    |-- price_in_usd: double (nullable = true)\n |    |    |-- quantity: long (nullable = true)\n |-- traffic_source: string (nullable = true)\n |-- user_first_touch_timestamp: long (nullable = true)\n |-- user_id: string (nullable = true)\n\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 3. Apply transformations to filter and sort **`macOS`** events\n- Filter for rows where **`device`** is **`macOS`**\n- Sort rows by **`event_timestamp`**\n\n<img src=\"https://files.training.databricks.com/images/icon_hint_32.png\" alt=\"Hint\"> Use single and double quotes in your filter SQL expression"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"40941aec-7161-4b10-8c20-3de62b2d482f"}}},{"cell_type":"code","source":["# TODO\nmac_df = (events_df\n          .select(\"*\")\n          .where(\"device = 'macOS'\")\n          .orderBy(\"event_timestamp\")\n         )"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5a1906b-b53c-4910-90fd-3128719514ec"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### 4. Count results and take first 5 rows\n- Use DataFrame actions to count and take rows"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"27a5f970-3b64-4966-9253-d23da9f0ae88"}}},{"cell_type":"code","source":["# TODO\nnum_rows = mac_df.count()\nrows = mac_df.take(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"45e599e0-dbf0-44c9-bb52-84cd3850e388"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**4.1: CHECK YOUR WORK**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ec08b9b3-afc8-4e93-bcb5-238f40eca06c"}}},{"cell_type":"code","source":["from pyspark.sql import Row\n\nassert(num_rows == 1938215)\nassert(len(rows) == 5)\nassert(type(rows[0]) == Row)\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6ab12a0b-0b97-4ffd-bf96-6ec50d66a283"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"All test pass\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["All test pass\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### 5. Create the same DataFrame using SQL query\n- Use SparkSession to run a SQL query on the **`events`** table\n- Use SQL commands to write the same filter and sort query used earlier"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9a7b75ad-cd86-440f-850b-6e59956a6ce2"}}},{"cell_type":"code","source":["# TODO\nmac_sql_df = spark.sql(\"SELECT * FROM events WHERE device == 'macOS' ORDER BY event_timestamp\")\n\n# display(mac_sql_df)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e29bcff-920d-452b-96b5-1142af672f44"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["**5.1: CHECK YOUR WORK**\n- You should only see **`macOS`** values in the **`device`** column\n- The fifth row should be an event with timestamp **`1592539226602157`**"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9dfb41a7-cc82-4abb-b8ee-8f3243a267f0"}}},{"cell_type":"code","source":["verify_rows = mac_sql_df.take(5)\nassert (mac_sql_df.select(\"device\").distinct().count() == 1 and len(verify_rows) == 5 and verify_rows[0]['device'] == \"macOS\"), \"Incorrect filter condition\"\nassert (verify_rows[4]['event_timestamp'] == 1592539226602157), \"Incorrect sorting\"\ndel verify_rows\nprint(\"All test pass\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d33c9670-1248-4b2f-b0b2-c559ac923bc3"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"All test pass\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["All test pass\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["### Classroom Cleanup"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a759bfb-1cb9-4080-8cf4-1ed44f76b8b0"}}},{"cell_type":"code","source":["classroom_cleanup()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"99be08d6-e874-497a-b10c-352c3a495dd2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"Dropped the database dbacademy_si_elisaandgeeks_com_aspwd_asp_2_1l_spark_sql_lab\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["Dropped the database dbacademy_si_elisaandgeeks_com_aspwd_asp_2_1l_spark_sql_lab\n"]}}],"execution_count":0},{"cell_type":"markdown","source":["-sandbox\n&copy; 2022 Databricks, Inc. All rights reserved.<br/>\nApache, Apache Spark, Spark and the Spark logo are trademarks of the <a href=\"https://www.apache.org/\">Apache Software Foundation</a>.<br/>\n<br/>\n<a href=\"https://databricks.com/privacy-policy\">Privacy Policy</a> | <a href=\"https://databricks.com/terms-of-use\">Terms of Use</a> | <a href=\"https://help.databricks.com/\">Support</a>"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fb0513eb-7b71-4e68-9c8c-b5068201bed6"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"ASP 2.1L - Spark SQL Lab","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":2792364041656190}},"nbformat":4,"nbformat_minor":0}
